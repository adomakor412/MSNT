{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ronald Adomako\n",
    "\n",
    "HW 1\n",
    "\n",
    "IST_5200\n",
    "\n",
    "Data Science and Machine Learning with Python\n",
    "\n",
    "Professor Langtao Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book 1 Chapter 2:\n",
    "### Problems 2.1, 2.2, 2.5, 2.6, 2.7, and 2.10.  Each problem deserves 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1\n",
    "Assuming that data mining techniques are to be used in the following cases, identify\n",
    "whether the task required is supervised or unsupervised learning.\n",
    "#### a. SUPERVISED\n",
    "Deciding whether to issue a loan to an applicant based on demographic and financial\n",
    "data (with reference to a database of similar data on prior customers).\n",
    "#### b. UNSUPERVISED\n",
    "In an online bookstore, making recommendations to customers concerning additional\n",
    "items to buy based on the buying patterns in prior transactions.\n",
    "#### c. SUPERVISED\n",
    "Identifying a network data packet as dangerous (virus, hacker attack) based on comparison\n",
    "to other packets whose threat status is known.\n",
    "#### d. UNSUPERVISED\n",
    "Identifying segments of similar customers.\n",
    "#### e. SUPERVISED\n",
    "Predicting whether a company will go bankrupt based on comparing its financial data\n",
    "to those of similar bankrupt and nonbankrupt firms.\n",
    "#### f. UNSUPERVISED\n",
    "Estimating the repair time required for an aircraft based on a trouble ticket.\n",
    "#### g. SUPERVISED\n",
    "Automated sorting of mail by zip code scanning.\n",
    "#### h. UNSUPERVISED\n",
    "Printing of custom discount coupons at the conclusion of a grocery store checkout\n",
    "based on what you just bought and what others have bought previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 \n",
    "Describe the difference in roles assumed by the validation partition and the test partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • The validation partition is used assess the accuracy of the primary model. The test partition is used for an alternate model otherwise known to be used for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 \n",
    "Using the concept of overfitting, explain why when a model is fit to training data, zero error with those data is not necessarily good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Zero error on the training data assumes there is no noise in the data. Therefore, if there is noise in the the validation set, then the model won't be able to predict it leading to an inaccurate model. Chances are the data has noise. Machine learning models account for residuals (the difference from discrete result to true result) to better predict new data leading to an overall more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 \n",
    "In fitting a model to classify prospects as purchasers or nonpurchasers, a certain company\n",
    "drew the training data from internal data that include demographic and purchase\n",
    "information. Future data to be classified will be lists purchased from other sources, with\n",
    "demographic (but not purchase) data included. It was found that “refund issued” was a\n",
    "useful predictor in the training data. Why is this not an appropriate variable to include\n",
    "in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Because refunds would not accompany the new data, it is best to leave it out of the model to predict new data although it was relevant to the training partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7\n",
    "A dataset has 1000 records and 50 variables with 5% of the values missing, spread randomly\n",
    "throughout the records and variables. An analyst decides to remove records with missing\n",
    "values. About how many records would you expect to be removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Because we remove rows (records) that are missing and not variables (columns) we can expect 5% of the records to be removed. Note that the remaining data will have rows that have some missing data variables, but not entirely empty.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.10\n",
    "\n",
    "Two models are applied to a dataset that has been partitioned. Model A is considerably\n",
    "more accurate than model B on the training data, but slightly less accurate than model B\n",
    "on the validation data. Which model are you more likely to consider for final deployment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Model A is overfitting on the training data. Choose Model B for deployment, since it is more accurate on the validation partition compared to the training partition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
